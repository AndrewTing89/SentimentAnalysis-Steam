{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "851d0afa-3cdc-4cc6-977b-948085cb67dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/SentimentAnalysis-Steam\n",
      "env: GCS_BUCKET_NAME=steam-reviews-bucket-0\n",
      "env: GCS_DATA_FILE_PATH=steam_reviews_cleaned.csv\n",
      "env: BQ_PROJECT_ID=sentiment-analysis-steam\n",
      "env: BQ_DATASET_ID=steam_reviews\n",
      "env: BQ_RAW_TABLE_ID=raw_reviews\n",
      "env: REGION=us-west1 # Ensure this matches your bucket/project region for BQ dataset location\n",
      "Current working directory: /home/jupyter/SentimentAnalysis-Steam\n",
      "Environment variables set for testing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup Environment Variables & Navigate\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "\n",
    "# --- Navigate to your project root ---\n",
    "# This ensures that your subsequent paths (e.g., to ingestion_service/) are correct.\n",
    "%cd /home/jupyter/SentimentAnalysis-Steam/\n",
    "\n",
    "# --- Set environment variables for local testing ---\n",
    "# These are the variables your ingestion_app.py expects.\n",
    "# They will be set for this Python session and its child processes.\n",
    "%env GCS_BUCKET_NAME=steam-reviews-bucket-0\n",
    "%env GCS_DATA_FILE_PATH=steam_reviews_cleaned.csv\n",
    "%env BQ_PROJECT_ID=sentiment-analysis-steam\n",
    "%env BQ_DATASET_ID=steam_reviews\n",
    "%env BQ_RAW_TABLE_ID=raw_reviews\n",
    "%env REGION=us-west1 # Ensure this matches your bucket/project region for BQ dataset location\n",
    "\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(\"Environment variables set for testing.\")\n",
    "\n",
    "# IMPORTANT: Ensure your local GCP authentication is set up.\n",
    "# You need to have run 'gcloud auth application-default login' once in your JupyterLab terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f784d04-1c40-42ab-8cd4-81cd003b5652",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ingestion_app.py in the background...\n",
      "Ingestion app started. Check 'ingestion_app_local.log' for logs.\n",
      "Giving the app a moment to start up...\n",
      "⚠️ App health check failed with status 405.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Run ingestion_app.py Locally in the Background\n",
    "\n",
    "# We'll store the process object globally so we can stop it later.\n",
    "global ingestion_app_process\n",
    "\n",
    "# Check if a process is already running to avoid multiple instances\n",
    "if 'ingestion_app_process' in globals() and ingestion_app_process.poll() is None:\n",
    "    print(\"Ingestion app is already running. Terminating previous process...\")\n",
    "    ingestion_app_process.terminate()\n",
    "    ingestion_app_process.wait()\n",
    "    time.sleep(1) # Give it a moment to shut down\n",
    "\n",
    "print(\"Starting ingestion_app.py in the background...\")\n",
    "\n",
    "# Use subprocess.Popen to run the Flask app as a non-blocking process.\n",
    "# We redirect stdout/stderr to files so we can inspect logs later if needed.\n",
    "# Ensure the path to ingestion_app.py is correct relative to your current CWD (which is /home/jupyter/SentimentAnalysis-Steam/)\n",
    "log_file_path = \"ingestion_app_local.log\"\n",
    "with open(log_file_path, \"w\") as outfile:\n",
    "    ingestion_app_process = subprocess.Popen(\n",
    "        [\"python\", \"ingestion_service/ingestion_app.py\"],\n",
    "        stdout=outfile,\n",
    "        stderr=subprocess.STDOUT, # Redirect stderr to stdout file\n",
    "        text=True, # Handle output as text\n",
    "        bufsize=1 # Line-buffered output\n",
    "    )\n",
    "\n",
    "print(f\"Ingestion app started. Check '{log_file_path}' for logs.\")\n",
    "print(\"Giving the app a moment to start up...\")\n",
    "time.sleep(10) # Give the Flask app some time to initialize and bind to the port\n",
    "\n",
    "# Optional: Ping the health check endpoint to confirm it's up\n",
    "try:\n",
    "    health_check_response = requests.get(\"http://localhost:8081/\")\n",
    "    if health_check_response.status_code == 200:\n",
    "        print(\"✅ App health check passed: Local server is responding.\")\n",
    "    else:\n",
    "        print(f\"⚠️ App health check failed with status {health_check_response.status_code}.\")\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"❌ App health check failed: Could not connect to local server. Check logs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4edbef5c-c39e-432f-9784-fb8529cb6d41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending POST request to http://localhost:8081/...\n",
      "✅ Request successful!\n",
      "Response status code: 200\n",
      "Response JSON: {'message': 'Raw data ingested to BigQuery.', 'status': 'success'}\n",
      "\n",
      "--- Last 20 lines of local app logs ---\n",
      "→ Grand Theft Auto V Legacy: page 17/50, got 100 reviews.\n",
      "→ Grand Theft Auto V Legacy: page 18/50, got 100 reviews.\n",
      "→ Grand Theft Auto V Legacy: page 19/50, got 100 reviews.\n",
      "→ Grand Theft Auto V Legacy: page 20/50, got 100 reviews.\n",
      "→ Grand Theft Auto V Legacy: page 21/50, got 100 reviews.\n",
      "→ Grand Theft Auto V Legacy: page 22/50, got 100 reviews.\n",
      "→ Grand Theft Auto V Legacy: page 23/50, got 100 reviews.\n",
      "→ Grand Theft Auto V Legacy: page 24/50, got 100 reviews.\n",
      "→ Grand Theft Auto V Legacy: page 25/50, got 100 reviews.\n",
      "→ Grand Theft Auto V Legacy: page 26/50, got 100 reviews.\n",
      "→ Grand Theft Auto V Legacy: page 27/50, got 100 reviews.\n",
      "→ Grand Theft Auto V Legacy: page 28/50, got 100 reviews.\n",
      "→ Grand Theft Auto V Legacy: page 29/50, got 100 reviews.\n",
      "→ Grand Theft Auto V Legacy: page 30/50, got 100 reviews.\n",
      "→ Grand Theft Auto V Legacy: page 31/50, got 100 reviews.\n",
      "→ Grand Theft Auto V Legacy: page 32/50, got 100 reviews.\n",
      "→ Grand Theft Auto V Legacy: page 33/50, got 100 reviews.\n",
      "→ Grand Theft Auto V Legacy: page 34/50, got 100 reviews.\n",
      "→ Grand Theft Auto V Legacy: page 35/50, got 100 reviews.\n",
      "127.0.0.1 - - [08/Jul/2025 20:13:14] \"POST / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Send Test Request to Local App\n",
    "\n",
    "# The URL of your locally running Flask app\n",
    "LOCAL_APP_URL = \"http://localhost:8081/\"\n",
    "\n",
    "print(f\"Sending POST request to {LOCAL_APP_URL}...\")\n",
    "\n",
    "try:\n",
    "    # Send a simple POST request (body can be empty JSON for your current app)\n",
    "    response = requests.post(LOCAL_APP_URL, json={})\n",
    "    response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
    "\n",
    "    print(\"✅ Request successful!\")\n",
    "    print(\"Response status code:\", response.status_code)\n",
    "    print(\"Response JSON:\", response.json())\n",
    "\n",
    "except requests.exceptions.ConnectionError as e:\n",
    "    print(f\"❌ Connection Error: Could not connect to the local server.\")\n",
    "    print(f\"   Make sure 'ingestion_app.py' is running in a separate terminal on port 8080 or check logs in '{log_file_path}'.\")\n",
    "    print(f\"   Error details: {e}\")\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(f\"❌ HTTP Error: Server responded with {e.response.status_code}.\")\n",
    "    print(f\"   Response: {e.response.text}\")\n",
    "    print(f\"   Error details: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ An unexpected error occurred: {e}\")\n",
    "\n",
    "# Optional: View recent logs from the background process\n",
    "print(\"\\n--- Last 20 lines of local app logs ---\")\n",
    "try:\n",
    "    with open(log_file_path, \"r\") as f:\n",
    "        log_lines = f.readlines()\n",
    "        for line in log_lines[-20:]: # Print last 20 lines\n",
    "            print(line.strip())\n",
    "except FileNotFoundError:\n",
    "    print(\"Log file not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a466c3d9-6e06-4438-a434-834776bae8d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminating ingestion app process...\n",
      "App process stopped.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Stop the Local App\n",
    "import time\n",
    "\n",
    "if 'ingestion_app_process' in globals() and ingestion_app_process.poll() is None:\n",
    "    print(\"Terminating ingestion app process...\")\n",
    "    ingestion_app_process.terminate() # Request termination\n",
    "    ingestion_app_process.wait(timeout=5) # Wait for it to terminate\n",
    "    if ingestion_app_process.poll() is None: # Check if it's still running\n",
    "        print(\"Process did not terminate gracefully, killing it.\")\n",
    "        ingestion_app_process.kill() # Force kill if it's stuck\n",
    "    print(\"App process stopped.\")\n",
    "else:\n",
    "    print(\"Ingestion app is not running.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a722af7-6712-4530-ae9f-0b022aa2e68e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m130",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m130"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
